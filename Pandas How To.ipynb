{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "## AUTHOR: L.O.V.Edwards\n",
    "## Date: Feb 28/2023 \n",
    "# Purpose\n",
    "The purpose of the notebook is to introduce Pandas data structures, in particular, DataFrames. We begin by discussing series versus DataFrames, and then dive into using DataFrames. \n",
    "\n",
    "    1. We begin with a discussion of Pandas data structures.\n",
    "    2. We use a Pokemon dataset as an example to highlight how to manipulate Pandas DataFrames.\n",
    "    3. We spend some time learning how to handle missing data.\n",
    "    4. We end with a task/discussion to develop future tutorial elements that will implement what we learn on this dataset, to a Rubin DP0.2 context\n",
    "\n",
    "This tutorial is created for undergraduate students beginning their adventures in Python, and  preparing to use the LSST DP0 data and its associated tutorials. It is based on a tutorial that was created for the Edwards galaxy Lab by Emily Claire. The original is available at: https://github.com/ledwar04/Pandas_How_Tohttps://github.com/ledwar04/Pandas_How_To\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What are main Pandas Data Structures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will go over how to create and manipulate Pandas Series and DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Pandas\n",
    "\n",
    "To import Pandas type:\n",
    "<br> 'import pandas as pd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#How to import pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information on Series and DataFrames "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### What is a Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use a DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame from a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Whole CSV File\n",
    "\n",
    "If you want to import everything from your .csv file then you use this code, where my_dataframe is the name of the dataframe you are creating and my_csv.csv is the name of file that already exists that you are importing.\n",
    "\n",
    "`my_dataframe = pd.read_csv('my_csv.csv')`\n",
    "\n",
    "`'my_csv.csv'` is the location of the csv file relative to where the jupyter notebook is. If the file is in the same folder as the jupyter notebook then you can just use the name of the file. If the file is somewhere else then you have to use the path of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#File in same folder\n",
    "pokemon = pd.read_csv('pokemon.csv')\n",
    "\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#File in a sub folder called example\n",
    "\n",
    "digimon = pd.read_csv('example/DigiDB_digimonlist.csv')\n",
    "\n",
    "digimon.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Specific Columns from a CSV file\n",
    "If you only want certain columns from a csv file, then you need to use 'usecols'. \n",
    "<br> Example:  `my_dataframe = pd.read_csv('my_csv.csv', usecols = ['Name of column1', 'Name of column 2'])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pokemon_name_types = pd.read_csv('pokemon.csv', usecols = ['Name', 'Type 1', 'Type 2'])\n",
    "\n",
    "pokemon_name_types.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Manipulating a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new DataFrame from specific data from 1 specific column\n",
    "\n",
    "Let's say you want to only access items that have a specific value in a certain column. \n",
    "<br> You would use the code `my_specific_items = my_dataframe.loc[my_dataframe['Column Name'] == 'Column Value']`\n",
    "<br> You can also use other boolean operations like less than, greater than, etc\n",
    "<br> `my_specific_items = my_dataframe.loc[my_dataframe['Column Name'] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Getting the digimon that have speed > 70\n",
    "pokemon_fast = pokemon.loc[pokemon['Speed'] > 120]\n",
    "\n",
    "pokemon_fast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T20:53:26.334271Z",
     "iopub.status.busy": "2023-02-27T20:53:26.333483Z",
     "iopub.status.idle": "2023-02-27T20:53:26.338623Z",
     "shell.execute_reply": "2023-02-27T20:53:26.337900Z",
     "shell.execute_reply.started": "2023-02-27T20:53:26.334237Z"
    }
   },
   "source": [
    "### Creating a new Series that is the result of algebraic manipulation of previous DataFrame elements\n",
    "\n",
    "Let's say you want to create a new series that is the result of the algebraic manipulation of a column of a DataFrame. You can use *, -, /, -.\n",
    "<br> You would use the code `my_specific_items = value / my_dataframe.loc[my_dataframe['Column Name'] == 'Column Value']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Getting the digimon that have speed > 70, but changing to km/s instead of m/s\n",
    "pokemon_kms = pokemon['Speed'] / 1000.\n",
    "\n",
    "pokemon_kms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new DataFrame from specific data from multiple columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select specific parts of dataframes by using ()'s, &, and |\n",
    "\n",
    "`my_dataframe = my_dataframe[(my_dataframe.column_name < value) & (my_dataframe.column_name == value)]`\n",
    "\n",
    "is the same as \n",
    "\n",
    "`my_dataframe = my_dataframe[(my_dataframe['column_name'] < value) & (my_dataframe['column_name'] == value)]` \n",
    "\n",
    "because `my_dataframe.key` is the same as `my_dataframe['key']`. Just be consistent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to get all the digimon that had the attribute Neutral or Light and were in stage Mega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mega_light_or_neutral = digimon[(digimon.Stage == 'Mega') & \n",
    "                                ((digimon.Attribute == 'Light') | (digimon.Attribute == 'Neutral'))]\n",
    "\n",
    "mega_light_or_neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've imported a csv file that has missing data. The missing data is represented by NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruit_in_pie = pd.read_csv('example_nan.csv')\n",
    "\n",
    "fruit_in_pie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see how many NaN values are in each column, then you type `my_dataframe.isnull().sum()` where my_dataframe is the name of the dataframe you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruit_in_pie.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see how many NaN values are in each row, then you type `my_dataframe.isnull().sum(axis = 1)`\n",
    "\n",
    "The default axis is axis = 0, which represents the columns. The rows are represented by axis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruit_in_pie.isnull().sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to find out how many total NaN values you have than you do type `my_dataframe.isnull().sum().sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruit_in_pie.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing NaN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can remove NaN values by removing any columns that contain NaN's or removing any rows that have NaN's.\n",
    "\n",
    "for more detailed information see https://pandas.pydata.org/docs/user_guide/missing_data.htmlhttps://pandas.pydata.org/docs/user_guide/missing_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Columns with NaN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create a new data frame without columns that have NaN's (so without Bananas and Apples) then you type `my_dataframe_without_NaN = my_dataframe.dropna(axis = 1)` \n",
    "\n",
    "If you want to just remove the columns with NaNs from your original dataframe, then you type `my_dataframe.dropna(axis = 1, inplace = True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Removes all columns with NaN values\n",
    "no_nan_in_cols = fruit_in_pie.dropna(axis = 1)\n",
    "\n",
    "no_nan_in_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create a new data frame without rows that have NaN's (so without rows 0, 1, 3, 4) then you type <br>`my_dataframe_without_NaN = my_dataframe.dropna(axis = 0)` <br>or <br>`my_dataframe_without_NaN = my_dataframe.dropna()` because the default value of axis is 0.\n",
    "\n",
    "If you want to just remove the rows with NaNs from your original dataframe, then you type <br>`my_dataframe.dropna(axis = 0, inplace = True)`<br> or <br>`my_dataframe.dropna(inplace = True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Removes all rows with NaN values\n",
    "#default does axis = 0\n",
    "no_nan_in_rows = fruit_in_pie.dropna()\n",
    "no_nan_in_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing NaN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is helpful to replace NaNs with a specific value. Below we show how to replace all NaNs with a -99 value, then, how to replace NaNs in a particular Column, and finally how to replace a NaN at a particular column and row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_nan = fruit_in_pie.fillna(-99)\n",
    "replace_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruit_in_pie['Apples'].fillna(50, inplace = True)\n",
    "fruit_in_pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruit_in_pie.loc[3, 'Bananas'] = 100\n",
    "fruit_in_pie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T22:12:04.742400Z",
     "iopub.status.busy": "2023-02-27T22:12:04.741720Z",
     "iopub.status.idle": "2023-02-27T22:12:04.744742Z",
     "shell.execute_reply": "2023-02-27T22:12:04.744242Z",
     "shell.execute_reply.started": "2023-02-27T22:12:04.742370Z"
    },
    "tags": []
   },
   "source": [
    "## 4. How to practice with DP0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss and write down your ideas for implementing some of these types of tasks on DP0.2 data. Prize for individuals (or groups) who develop a tutorial element that I use next year in the workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Resources\n",
    "\n",
    "How to make dataframes from csv files - https://pandas.pydata.org/docs/user_guide/io.htmlhttps://pandas.pydata.org/docs/user_guide/io.html\n",
    "<br>digimon csv file - https://www.kaggle.com/rtatman/digidb\n",
    "<br> How to use get specific columns from a csv file - https://stackoverflow.com/questions/26063231/read-specific-columns-with-pandas-or-other-python-module\n",
    "<br> How to combine DataFrames - https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.htmlhttps://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Answers\n",
    "A Pandas Series is like a column in a table. It is a one-dimensional array holding data of any type. This is the primary pandas data structure.\n",
    "\n",
    "A Pandas DataFrame is like a table. It is a Two-dimensional, potentially heterogeneous tabular data structure. This data structure contains labeled axes (rows and columns). Arithmetic operations align on both row and column labels. It can be thought of as a dict-like container for Series objects. \n",
    "\n",
    "I should use a Series when the data is one-dimentional and all of the same type.\n",
    "\n",
    "I should use a DataFrame when the data is two-dimentonal and the DataFame elements have different column types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Possible code snippet for DP0.2 data. \n",
    "To run the following cells, you'll need to properly import the TAP requirements, as in Tutorials 1 and 2 for the Notebooks aspect from within DP0.2 found. More information here: https://dp0-2.lsst.io/tutorials-examples/index.html\n",
    "\n",
    "The first cell sets up a TAP query, the second cell manipulates the results in Pandas format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# set up a tap query to get a list of bright galaxies near a cluster\n",
    "\n",
    "#joins object and truth data for bright galaxies around an ra,dec location\n",
    "\n",
    "def runTAPobjplustruth(ra, dec, size):\n",
    "    \"\"\"\n",
    "    Get tables of observed galaxies from the tap\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ra : ra\n",
    "    dec : dec\n",
    "    size: in degrees\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    truth_plus_meas: table of truth table matched to objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the query   \n",
    "    query = \"SELECT mt.id_truth_type AS mt_id_truth_type, \"\\\n",
    "        \"mt.match_objectId AS mt_match_objectId, \"\\\n",
    "        \"ts.ra AS ts_ra, \"\\\n",
    "        \"ts.dec AS ts_dec, \"\\\n",
    "        \"ts.truth_type AS ts_truth_type, \"\\\n",
    "        \"ts.mag_r AS ts_mag_r, \"\\\n",
    "        \"ts.redshift AS redshift, \"\\\n",
    "        \"obj.coord_ra AS ra, \"\\\n",
    "        \"obj.coord_dec AS dec, \"\\\n",
    "        \"obj.refExtendedness AS obj_refExtendedness, \"\\\n",
    "        \"scisql_nanojanskyToAbMag(obj.r_cModelFlux) AS mag_r_cModel, \"\\\n",
    "        \"scisql_nanojanskyToAbMag(obj.i_cModelFlux) AS mag_i_cModel \"\\\n",
    "        \"FROM dp02_dc2_catalogs.MatchesTruth AS mt \"\\\n",
    "        \"JOIN dp02_dc2_catalogs.TruthSummary AS ts ON mt.id_truth_type = ts.id_truth_type \"\\\n",
    "        \"JOIN dp02_dc2_catalogs.Object AS obj ON mt.match_objectId = obj.objectId \"\\\n",
    "        \"WHERE CONTAINS(POINT('ICRS', obj.coord_ra, obj.coord_dec), CIRCLE('ICRS', \"+str(ra)+\",\"+str(dec)+\",  \"+str(size)+\")) = 1 \"\\\n",
    "        \"AND ts.truth_type = 1 \"\\\n",
    "        \"AND ts.mag_r < 21 \"\n",
    "\n",
    "    print(query)\n",
    "    #get the results from the photometric catalog\n",
    "    truth_plus_meas = service.search(query, maxrec=50000)\n",
    "    return truth_plus_meas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T22:24:16.223741Z",
     "iopub.status.busy": "2023-02-27T22:24:16.223120Z",
     "iopub.status.idle": "2023-02-27T22:24:16.236546Z",
     "shell.execute_reply": "2023-02-27T22:24:16.235874Z",
     "shell.execute_reply.started": "2023-02-27T22:24:16.223720Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# fetch a list of galaxies around a cluster core from DP0.2 using a TAP query\n",
    "ra, dec = 55.7506655, -32.2722637\n",
    "size = 0.5 #in degrees\n",
    "  \n",
    "# save the output as a Table, then as a Pandas DataFrame\n",
    "`truth_plus_meas = runTAPobjplustruth(ra, dec, size)`\n",
    "\n",
    "`tresults_tab = truth_plus_meas.to_table()`\n",
    "\n",
    "`truthdata = tresults_tab.to_pandas()`\n",
    "\n",
    "# In your own words, what does the following line do? Is the result a Series or a DataFrame?\n",
    "`clustertruthdata = truthdata[(truthdata['redshift']<0.2) & (truthdata['redshift']>0.15) & (truthdata['ts_mag_r']<22)]`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
